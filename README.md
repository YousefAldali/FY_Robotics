| Test ID | Category                | What We’re Checking                          | Description (What We actually do)                                                                 | What We Expect to Happen                                                            | What We Measure                                           |
|---------|--------------------------|----------------------------------------------|-----------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|-----------------------------------------------------------|
| T1      | Mapping (SLAM)           | How good our LiDAR map is                    | We let the robot explore a simple room and build an occupancy grid using LiDAR + odometry.          | The map should look close to the real room, without big errors or distortion.       | Map accuracy, drift, number of scans                      |
| T2      | Localisation             | How stable the robot’s position estimate is  | We drive the robot down a corridor and watch how consistent its SLAM localisation stays.            | Position should stay stable — no sudden “teleporting” jumps.                        | Error in (x, y, θ) and drift over time                    |
| T3      | Navigation               | Basic point-to-point movement                | Robot moves from Room A → Room B using normal path planning.                                        | Takes a clean, collision-free path.                                                  | Path length, time taken, collision count                  |
| T4      | Social Distance (Proxemics) | Whether the robot avoids entering personal space | We place a human model in the environment, then send the robot to a goal behind the human.        | Robot chooses a path around the human instead of cutting too close.                 | Minimum robot-human distance, path deviation              |
| T5      | Guidance Behaviour       | Can the robot lead a person?                 | A simulated human follows the robot at ~1–1.5 m. We watch how steady the robot keeps this distance. | Robot stays ahead at a comfortable, predictable distance.                            | Mean distance + variance, oscillations                    |
| T6      | Comfort Profiles         | Switching between social distance presets    | We test (conservative), (neutral), and (open) proxemic profiles while navigating around a human.    | Robot adjusts its distances correctly for each profile.                              | Avg robot-human distance, path smoothness                 |
| T7      | Trajectory Smoothness    | How smooth the motion looks                  | Robot drives through a long corridor with turns, and we analyse motion curvature.                    | No sudden jerks or sharp unnatural turns.                                           | Curvature score, angular acceleration                     |
| T8      | Obstacle Avoidance       | Avoiding random objects during guidance      | We put chairs/boxes in the way while robot guides the human.                                         | Robot avoids obstacles safely while still respecting human space.                    | Clearance to obstacles, collision rate                    |
| T9      | Ethical/Safe Behaviour   | Predictability + safety around dementia patients | We observe the robot near a dementia-patient actor.                                               | Robot moves calmly, slowly, predictably — no sudden behaviour.                       | Max speed, acceleration, time to human, safety triggers   |
| T10     | Full System Test         | Everything together                           | Start from an unknown map → robot explores → maps → localises → finds human → guides them.          | Entire pipeline works: mapping + localisation + social navigation + guidance.        | Success rate, task duration, distance to human, map quality |
